{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T16:22:22.310189Z",
     "start_time": "2020-03-30T16:22:21.843593Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'trace_reconstruction_heuristics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-714d66909ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeletion_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minference_metaheuristics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrace_reconstruction_heuristics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trace_reconstruction_heuristics'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "from numba import jit,prange\n",
    "\n",
    "from helper_functions import *\n",
    "from deletion_functions import *\n",
    "from inference_metaheuristics import *\n",
    "from trace_reconstruction_heuristics import *\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import multiprocessing as mp\n",
    "from itertools import repeat\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:17:49.304023Z",
     "start_time": "2020-03-23T17:17:49.290807Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def one_iter(N,A,T_s,delta, method = None, method_params = None):\n",
    "    \n",
    "    X = randseq_uniform(N,A)\n",
    "#     print(X[-20:])\n",
    "    Y_list = []\n",
    "    \n",
    "    hamming_error_rates = []\n",
    "    \n",
    "    for t in range(1,max(T_s)+1):\n",
    "        Y_list.append(dc(X,delta))\n",
    "        \n",
    "        if t in T_s:\n",
    "            if method == 'proj_grad_asc_traces':\n",
    "                Xhat = proj_grad_asc_traces(method_params['P_init'],Y_list,lambda_grad,\\\n",
    "                                     lambda_forward,delta,step_size = 0.1,\\\n",
    "                                     tolerance = 1e-6,max_grad_steps = 100)\n",
    "            elif method == 'symbolwise_map_seq':\n",
    "                Xhat = symbolwise_map_seq(method_params['P_init'],Y_list,lambda_forward,lambda_grad,delta)\n",
    "            \n",
    "            elif method == 'ind_sources_comb':\n",
    "                Xhat = ind_sources_comb(method_params['P_init'],Y_list,lambda_forward,lambda_grad,delta)\n",
    "                \n",
    "            elif method == 'symbolwise_map_exact':\n",
    "                Xhat = symbolwise_map_exact(method_params['P_init'],Y_list,delta)\n",
    "            else:\n",
    "                raise ValueError('Method not implemented')\n",
    "            \n",
    "            hamming_error_rates.append(hamming_error_rate(Xhat,X))\n",
    "    \n",
    "#     print(X,Xhat)\n",
    "    return np.array(hamming_error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:18:05.674304Z",
     "start_time": "2020-03-23T17:18:05.639268Z"
    }
   },
   "outputs": [],
   "source": [
    "##### Warming up numba and the functions #####\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "N = 10\n",
    "A = 2\n",
    "T_s = [1]\n",
    "delta = 0.2\n",
    "\n",
    "method = 'proj_grad_asc_traces'\n",
    "method_params = {}\n",
    "method_params['P_init'] = 1/A * np.ones((N,A))\n",
    "one_iter(N,A,T_s,delta, method, method_params)\n",
    "\n",
    "method = 'symbolwise_map_seq'\n",
    "method_params = {}\n",
    "method_params['P_init'] = 1/A * np.ones((N,A))\n",
    "one_iter(N,A,T_s,delta, method, method_params)\n",
    "\n",
    "method = 'symbolwise_map_exact'\n",
    "method_params = {}\n",
    "method_params['P_init'] = 1/A * np.ones((N,A))\n",
    "one_iter(N,A,T_s,delta, method, method_params)\n",
    "\n",
    "method = 'ind_sources_comb'\n",
    "method_params = {}\n",
    "method_params['P_init'] = 1/A * np.ones((N,A))\n",
    "one_iter(N,A,T_s,delta, method, method_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:18:08.181733Z",
     "start_time": "2020-03-23T17:18:08.168628Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 50\n",
    "A = 2\n",
    "T_s = [1]\n",
    "delta = 0.2\n",
    "\n",
    "method = 'symbolwise_map_seq'\n",
    "method_params = {}\n",
    "method_params['P_init'] = 1/A * np.ones((N,A))\n",
    "one_iter(N,A,T_s,delta, method, method_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:18:14.294488Z",
     "start_time": "2020-03-23T17:18:14.280092Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_error_rates(N,A,T_s,delta_vec, method = None, method_params = None, hyperiters = 100,process_per_hyperiter = 100):\n",
    "    \n",
    "    results = {}\n",
    "    results['summary'] = (\"Hamming error rates and likelihood gains for a blocklength of {}, \"\n",
    "    \"an alphabet size {} using the method {}\".format(N,A,method))\n",
    "    \n",
    "    results['delta_vec'] = delta_vec\n",
    "    \n",
    "    hamming_error_list = np.zeros((len(delta_vec),len(T_s)))\n",
    "    #likelihood_gain_list = np.zeros((len(delta_vec),hyperiters*process_per_hyperiter))\n",
    "    \n",
    "    for idx in tnrange(len(delta_vec),desc = 'Delta values'):\n",
    "#         print('Computing for delta = ',delta)\n",
    "        delta = delta_vec[idx]\n",
    "        time.sleep(0.4)\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        for it in tnrange(hyperiters, desc = 'Hyperiters'):\n",
    "            temp = pool.starmap(one_iter, zip(repeat(N),repeat(A),repeat(T_s),delta*np.ones(process_per_hyperiter),\\\n",
    "                                              repeat(method),repeat(method_params)))\n",
    "            temp = np.array(temp)\n",
    "            hamming_error_list[idx,:] += temp.sum(axis = 0)\n",
    "            #likelihood_gain_list[idx,it*process_per_hyperiter:(it+1)*process_per_hyperiter] = temp[:,1]\n",
    "        pool.close()\n",
    "    \n",
    "    hamming_error_list /= hyperiters * process_per_hyperiter\n",
    "    results['hamming_error_list'] = hamming_error_list\n",
    "#     results['likelihood_gain_list'] = likelihood_gain_list\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:29:53.948061Z",
     "start_time": "2020-03-23T17:29:33.539663Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "N = 100\n",
    "A = 2\n",
    "T_s = [1]\n",
    "delta_vec = np.arange(0.1,0.6,0.1)\n",
    "\n",
    "hyperiters = 40\n",
    "process_per_hyperiter = 40\n",
    "\n",
    "errors = {}\n",
    "\n",
    "methods = ['symbolwise_map_seq','ind_sources_comb']\n",
    "\n",
    "for method in methods:\n",
    "    print('*'*50,'\\n',method,'\\n','*'*50)\n",
    "    method_params = {}\n",
    "    method_params['P_init'] = 1/A * np.ones((N,A))\n",
    "    errors[method] = gen_error_rates(N,A,T_s,delta_vec, method, method_params,hyperiters,process_per_hyperiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T23:10:00.774280Z",
     "start_time": "2020-03-10T23:10:00.766426Z"
    }
   },
   "outputs": [],
   "source": [
    "errors['symbolwise_map_seq']['hamming_error_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:30:37.006607Z",
     "start_time": "2020-03-23T17:30:36.872069Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(errors['proj_grad_asc_traces']['hamming_error_list'],marker = 's',markersize = 10)\n",
    "plt.plot(errors['symbolwise_map_seq']['delta_vec'], \n",
    "         errors['symbolwise_map_seq']['hamming_error_list'][:,],marker = '*',markersize = 10)\n",
    "# plt.plot(errors['symbolwise_map_exact']['hamming_error_list'],marker = '^',markersize = 10)\n",
    "plt.plot(errors['ind_sources_comb']['delta_vec'],\n",
    "         errors['ind_sources_comb']['hamming_error_list'],marker = '>',markersize = 10)\n",
    "\n",
    "# plt.ylim(0,0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T23:39:15.927871Z",
     "start_time": "2020-03-04T23:39:15.922137Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('errors_BL40.npy',errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T21:36:03.918932Z",
     "start_time": "2020-03-06T21:36:03.912621Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.load('errors_BL500.npy',allow_pickle = True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
